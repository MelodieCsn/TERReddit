{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-b5cd6ccfdd11>, line 435)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-b5cd6ccfdd11>\"\u001b[0;36m, line \u001b[0;32m435\u001b[0m\n\u001b[0;31m    if coordinate[4] == \"US\":\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import urllib.request, json, unidecode\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import copy\n",
    "import re\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import webbrowser\n",
    "from nltk.corpus import ieer\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "limit = 300\n",
    "\n",
    "def addInUsa(text):\n",
    "    text =text+\" -> 1\\n\"\n",
    "    print(text)\n",
    "    with open(\"USA.rd\",\"a\") as file1:\n",
    "        file1.write(text)\n",
    "        file1.close()\n",
    "\n",
    "def addInOthers(text):\n",
    "    text = text+\" -> 0\\n\"\n",
    "    print(text)\n",
    "    with open(\"Others.rd\",\"a\") as file2:\n",
    "        file2.write(text)\n",
    "        file2.close()\n",
    "\n",
    "\n",
    "def isClean(title):\n",
    "    title=str(title)\n",
    "    if title.find(\"x\") >= 0:\n",
    "        k= title.find(\"x\")\n",
    "        if (k-1) >=0 and (not title[k-1].isalpha()):\n",
    "            return False\n",
    "        elif (k+1) < len(title) and ( not title[k+1].isalpha()):\n",
    "            return False\n",
    "    elif title.find(\"X\") >= 0:\n",
    "        k= title.find(\"X\")\n",
    "        if (k-1) >=0 and (not title[k-1].isalpha()):\n",
    "            return False\n",
    "        elif (k+1) < len(title) and (not title[k+1].isalpha()):\n",
    "            return False\n",
    "\n",
    "    elif title.find(\"√ó\") >= 0:\n",
    "        k= title.find(\"√ó\")\n",
    "        if (k-1) >=0 and (not title[k-1].isalpha()):\n",
    "            return False\n",
    "        elif (k+1) < len(title) and (not title[k+1].isalpha()):\n",
    "            return False\n",
    "\n",
    "    elif title.find(\"*\") >= 0:\n",
    "            k = title.find(\"*\")\n",
    "            if (k - 1) >= 0 and (not title[k - 1].isalpha()):\n",
    "                return False\n",
    "            elif (k + 1) < len(title) and (not title[k + 1].isalpha()):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def properNoun(lexical):\n",
    "    noun =\"\"\n",
    "\n",
    "    for i in range(len(lexical)):\n",
    "        if lexical[i][1]==\"NNP\" and str(lexical[i][0]).isalpha():\n",
    "            noun+=lexical[i][0]+\" \"\n",
    "        elif (i+1) < len(lexical) and str(lexical[i][0]).isalpha() and lexical[i-1][1]==\"NNP\" and lexical[i+1][1]==\"NNP\":\n",
    "            noun += lexical[i][0] + \" \"\n",
    "    if noun==\"\":\n",
    "        for i in range(len(lexical)):\n",
    "            if (lexical[i][1] == \"NN\" or lexical[i][1] == \"NNS\") and str(lexical[i][0]).isalpha() and str(lexical[i][0])[0].isupper():\n",
    "                noun += lexical[i][0] + \" \"\n",
    "            elif ((i + 1) < len(lexical) and (i-1) >=0) and lexical[i][1]!=\"IN\" and str(lexical[i][0]).isalpha() and ((lexical[i-1][1] == \"NN\" and lexical[i + 1][1] == \"NN\") or (lexical[i-1][1] == \"NNS\" and lexical[i + 1][1] == \"NNS\")):\n",
    "                noun += lexical[i][0] + \" \"\n",
    "\n",
    "    return noun.strip()\n",
    "\n",
    "def locateFormed(location):\n",
    "    list = \"\"\n",
    "    for triplet in location:\n",
    "        list += triplet[0][0]+\" \"\n",
    "    return list.strip()\n",
    "def cleanTitle(title, step):\n",
    "    if step==1:\n",
    "        title = str(title)\n",
    "        title = title.strip()\n",
    "\n",
    "        motif = re.compile(r\"\\d{1,}\")\n",
    "        list = motif.findall(title)\n",
    "        if len(list)>0:\n",
    "            for out in list:\n",
    "                title = title.replace(out,\"\")\n",
    "        indice = title.find(\"IG\")\n",
    "        if indice >= 0:\n",
    "            if (indice - 1) >= 0  and not title[indice - 1].isalpha():\n",
    "                title = title.replace(\"IG\", \"\")\n",
    "        indice = title.find(\"ig\")\n",
    "        if indice >= 0:\n",
    "            if (indice - 1) >= 0 and not title[indice - 1].isalpha() :\n",
    "                title = title.replace(\"ig\", \"\")\n",
    "\n",
    "        motif = re.compile(r\"[a-zA-Z]+[0-9]+\")\n",
    "        list = motif.findall(title)\n",
    "        if len(list) > 0:\n",
    "            for out in list:\n",
    "                title = title.replace(out, \"\")\n",
    "\n",
    "        title = title.replace(\"üòâ\", \"\")\n",
    "        title = title.replace(\"Ô∏è\",\"\")\n",
    "        title = title.replace(\"‚ù§\", \"\")\n",
    "        title=title.replace(\"[OC]\",\"\")\n",
    "        title = title.replace(\"{OC}\", \"\")\n",
    "        title = title.replace(\"{oc}\", \"\")\n",
    "        title = title.replace(\",OC \", \"\")\n",
    "        title = title.replace(\"OC, \", \"\")\n",
    "        title = title.replace(\"(OC)\", \"\")\n",
    "        title = title.replace(\"(oc), \", \"\")\n",
    "        title = title.replace(\"oc,\", \"\")\n",
    "        title = title.replace(\",oc \", \"\")\n",
    "        title = title.replace(\":\", \"\")\n",
    "        title = title.replace(\"[oc]\", \"\")\n",
    "        title = title.replace(\"(\", \"\")\n",
    "        title = title.replace(\")\", \"\")\n",
    "        title = title.replace(\"[\", \"\")\n",
    "        title = title.replace(\"]\", \"\")\n",
    "        title=title.replace(\" OC \",\"\")\n",
    "        title = title.replace(\" oc \", \"\")\n",
    "        indice = title.find(\"OC\")\n",
    "        if indice >= 0 and (indice+2)== len(title):\n",
    "            title = title.replace(\"OC\", \"\")\n",
    "        indice = title.find(\"oc\")\n",
    "        if indice >= 0 and (indice + 2) == len(title):\n",
    "            title = title.replace(\"oc\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if title[:3]==\"OC \" or title[:3]==\"oc \":\n",
    "            title = title[3:]\n",
    "        title = title.strip()\n",
    "        if (title.find(\"@\") >= 0):\n",
    "            indice = title.find(\"@\")\n",
    "            k = indice + 1\n",
    "            print(\" avant\",title)\n",
    "            while ( k < len(title) and title[k]!=\" \" ):\n",
    "                k = k + 1\n",
    "            title = title[:indice] + title[k:]\n",
    "            title = title.strip()\n",
    "\n",
    "\n",
    "        title = title.strip()\n",
    "\n",
    "        print(\"After clean :\",title)\n",
    "        return title\n",
    "    if step==2:\n",
    "\n",
    "        indice = title.find(\"x\")\n",
    "        if indice < 0:\n",
    "            indice = title.find(\"X\")\n",
    "            if indice < 0:\n",
    "                indice = title.find(\"√ó\")\n",
    "                if indice < 0:\n",
    "                    indice = title.find(\"*\")\n",
    "\n",
    "        if indice >=0 and ((indice-1)>=0 and not title[indice-1].isalpha()) and ((indice+1)<len(title) and not title[indice+1].isalpha()):\n",
    "            chain1 = str(title[:indice])\n",
    "            chain2 = str(title[indice+1:])\n",
    "            if len(chain1) > 0:\n",
    "                while len(chain1)>0 and not chain1[-1].isalpha():\n",
    "                    chain1 = chain1[:-1]\n",
    "                while len(chain1)>0 and not chain1[0].isalpha():\n",
    "                    chain1 = chain1[1:]\n",
    "            else:\n",
    "                chain1 = \"\"\n",
    "\n",
    "            if len(chain2) > 1:\n",
    "                while len(chain2)>0 and not chain2[0].isalpha():\n",
    "                    chain2 = chain2[1:]\n",
    "                while len(chain2)>0 and not chain2[-1].isalpha():\n",
    "                    chain2 = chain2[:-1]\n",
    "            else:\n",
    "                chain2 = \"\"\n",
    "\n",
    "            title = chain1+\" \"+chain2\n",
    "            while len(title)>0 and not title[-1].isalpha():\n",
    "                title = title[:-1]\n",
    "            title = title.strip()\n",
    "            print(\"After clean :\", title)\n",
    "            return title\n",
    "        elif (indice + 1) == len(title) and (indice-1)>= 0 and  not title[indice - 1].isalpha():\n",
    "            title = title[:-2]\n",
    "        elif (indice == 0) and (indice + 1 ) < len(title) and  not title[indice + 1].isalpha():\n",
    "            title = title[1:]\n",
    "        print(\"After clean :\", title)\n",
    "\n",
    "    return title\n",
    "\n",
    "def distanceBetweenCordinates(coord1, coord2):\n",
    "    coord1[0] = math.radians(coord1[0])\n",
    "    coord1[1] = math.radians(coord1[1])\n",
    "    coord2[0] = math.radians(coord2[0])\n",
    "    coord2[1] = math.radians(coord2[1])\n",
    "    SPHERE_TERRE = 6378137\n",
    "    DIST_LON = (coord2[0] - coord1[0]) / 2\n",
    "    DIST_LAT = (coord2[1] - coord1[1]) / 2\n",
    "    ETAPE1 = (math.sin(DIST_LAT)**2) + math.cos(coord1[1]) * math.cos(coord2[1]) * (math.sin(DIST_LON)**2)\n",
    "    ETAPE2 = 2 * math.atan2(math.sqrt(ETAPE1), math.sqrt(1 - ETAPE1))\n",
    "    resultat = (SPHERE_TERRE * ETAPE2) / 1000\n",
    "    return resultat\n",
    "\n",
    "def existNameSocialNetwork(title):\n",
    "\n",
    "    title = str(title)\n",
    "    indice = title.find(\"Insta\")\n",
    "    if indice < 0:\n",
    "        indice = title.find(\"Instagram\")\n",
    "        if indice < 0:\n",
    "            indice = title.find(\"instagram\")\n",
    "            if indice < 0:\n",
    "                indice = title.find(\"instaGram\")\n",
    "                if indice < 0:\n",
    "                    indice = title.find(\"insta\")\n",
    "                    if indice < 0:\n",
    "                        indice = title.find(\"Facebook\")\n",
    "                        if indice < 0:\n",
    "                            indice = title.find(\"facebook\")\n",
    "                            if indice < 0:\n",
    "                                indice = title.find(\"FaceBook\")\n",
    "                                if indice < 0:\n",
    "                                    indice = title.find(\"Fb\")\n",
    "                                    if indice < 0:\n",
    "                                        indice = title.find(\"fb\")\n",
    "                                        if indice < 0:\n",
    "                                            indice = title.find(\"FB\")\n",
    "\n",
    "\n",
    "    if indice >= 0:\n",
    "        indice = indice + 1\n",
    "        a = title[:indice-1]\n",
    "        while indice < len(title) and title[indice] != \" \":\n",
    "            indice = indice + 1\n",
    "        title = a+title[indice:]\n",
    "        return existNameSocialNetwork(title)\n",
    "    return title\n",
    "def geoNamesSearch(lieu):\n",
    "    lieu = lieu.replace(\" \", \"+\")       #remplace les espaces par des +\n",
    "    lieu = lieu.replace(\"'\", \"+\")       #remplace les apostrophes par des plus\n",
    "    lieu = unidecode.unidecode(lieu)    #pour retirer les accents !attention tester les c√©dilles\n",
    "\n",
    "    api = \"http://api.geonames.org/searchJSON?q=\"+lieu+\"&maxRows=1&username=projet_TER_reddit\"\n",
    "    #print(api)\n",
    "\n",
    "    with urllib.request.urlopen(api) as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "    #print(\"Taille:\", len(data))\n",
    "    if data['totalResultsCount'] == 0:\n",
    "        return -1\n",
    "\n",
    "    long = data['geonames'][0]['lng']\n",
    "    lat  = data['geonames'][0]['lat']\n",
    "    contry = \"\"\n",
    "    code = \"\"\n",
    "    name = \"\"\n",
    "    if \"countryName\" in data['geonames'][0] and \"countryCode\" in data['geonames'][0]:\n",
    "        contry = data['geonames'][0][\"countryName\"]\n",
    "        code = data['geonames'][0][\"countryCode\"]\n",
    "        name = data['geonames'][0][\"name\"]\n",
    "    else:\n",
    "        contry = data['geonames'][0][\"fcodeName\"]\n",
    "        code = data['geonames'][0][\"fcode\"]\n",
    "        name = data['geonames'][0][\"name\"]\n",
    "\n",
    "\n",
    "    list=[]\n",
    "\n",
    "    list.append(lieu)\n",
    "    list.append(long)\n",
    "    list.append(lat)\n",
    "    list.append(contry)\n",
    "    list.append(code)\n",
    "    list.append(name)\n",
    "    return list\n",
    "\n",
    "\n",
    "\n",
    "def findLocation(liste):\n",
    "    list = []\n",
    "    for triple in liste:\n",
    "        if len(triple[0][1]) >2 and  (triple[1]==\"GSP\" or triple[1]==\"GPE\" or triple[1]==\"ORGANIZATION\" or triple[1]==\"PERSON\"):\n",
    "            list.append(triple)\n",
    "    return list\n",
    "\n",
    "def equalsTextList(list1, list2):\n",
    "    if len(list1)!=len(list2):\n",
    "        return  False\n",
    "    for i in range(len(list2)):\n",
    "        if list1[i]!=list2[i][0][0]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def middleCheck(list1, list2):\n",
    "\n",
    "    #check ineteressant\n",
    "    composed = locateFormed(list2)\n",
    "    i = len(list1)-1\n",
    "    while i > 0 :\n",
    "        composed =list1[i][0][0]+\" \"+composed\n",
    "        find = geoNamesSearch(composed)\n",
    "        if find != -1:\n",
    "            return find\n",
    "        i= i-1\n",
    "\n",
    "        # check du list2\n",
    "    find = geoNamesSearch(locateFormed(list2))\n",
    "    if find != -1:\n",
    "        return find\n",
    "\n",
    "        # check pour list1\n",
    "    if len(list1) >= 2:\n",
    "            find = geoNamesSearch(locateFormed(list1))\n",
    "            if find != -1:\n",
    "                return find\n",
    "\n",
    "    #check dichotomique\n",
    "    i = 0\n",
    "    composed = \"\"\n",
    "    for word in reversed(list1):\n",
    "        composed = word[0][0] +\" \"+ composed+(\" \" if len(composed)>0 else \"\") + list2[i][0][0]\n",
    "        i = i+1\n",
    "        find = geoNamesSearch(composed)\n",
    "        if find != -1:\n",
    "            return  find\n",
    "\n",
    "    while i < len(list2):\n",
    "        composed  += \" \" + list2[i][0][0]\n",
    "        i = i+1\n",
    "        find = geoNamesSearch(locateFormed(composed))\n",
    "        if find != -1:\n",
    "            return find\n",
    "    composed = \"\"\n",
    "    for word in reversed(list2):\n",
    "        composed+=word[0][0]\n",
    "        find = geoNamesSearch(composed)\n",
    "        composed +=\" \"\n",
    "        if find != -1:\n",
    "            return find\n",
    "    return -1\n",
    "def fusion():\n",
    "    tab = []\n",
    "    p = pd.read_json(\"reddit.json\")\n",
    "    taille = p.shape[1] + 1\n",
    "    for i in p:\n",
    "        tab.append([p[i].title, p[i].afterClean, p[i].subreddit, p[i].url, p[i].body, p[i].location, p[i].longitude,\n",
    "                    p[i].latitude, p[i].contryName, p[i].contryCode, p[i].name])\n",
    "\n",
    "    f = pd.read_json(\"fusion.json\")\n",
    "    for i in f:\n",
    "        tab.append([f[i].title, f[i].afterClean, f[i].subreddit, f[i].url, f[i].body, f[i].location, f[i].longitude,\n",
    "                    f[i].latitude, f[i].contryName,\n",
    "                    f[i].contryCode, f[i].name])\n",
    "\n",
    "    tab = pd.DataFrame(tab,\n",
    "                       columns=['title', 'afterClean', 'subreddit', 'url', 'body', 'location', 'longitude', 'latitude',\n",
    "                                'contryName', 'contryCode', 'name'])\n",
    "\n",
    "    tab.to_json(\"reddit.json\", orient='index')\n",
    "\n",
    "\n",
    "def collectionFromReddit():\n",
    "    ok = 0\n",
    "\n",
    "    reddit = praw.Reddit ( client_id = 'tMRO7I9OYVnG7A' , client_secret = 'Ghudpyy79xN1dUv9-lIdRaiTswE' , user_agent = 'dassScraping' )\n",
    "    posts = []\n",
    "    ml_subreddit = reddit.subreddit('EarthPorn')\n",
    "    for post in ml_subreddit.hot(limit=limit):\n",
    "        print(\"Original title :\",post.title)\n",
    "        step =1\n",
    "        afterClean = existNameSocialNetwork(deepcopy(post.title))\n",
    "        afterClean=cleanTitle(afterClean,step)\n",
    "        print(\"It's cleaned ?\",isClean(afterClean))\n",
    "        while not isClean(afterClean) and step <=2:\n",
    "            step = step + 1\n",
    "            afterClean = cleanTitle(afterClean, step)\n",
    "            print(\"It's cleaned ?\", isClean(afterClean))\n",
    "        lexical = nltk.word_tokenize(afterClean)\n",
    "        lexical = nltk.pos_tag(lexical)\n",
    "        print(\"lexical:\",lexical)\n",
    "        proper = properNoun(lexical)\n",
    "        print(\"proper noun:\", proper)\n",
    "        if len(proper) > 0:\n",
    "            resultat = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(afterClean)))\n",
    "            print(\"Test :\",resultat.pos())\n",
    "            loc = findLocation(resultat.pos())\n",
    "            print(\"Location: \",loc)\n",
    "            coordinate = geoNamesSearch(proper)\n",
    "            print(\"geoNames:\", coordinate)\n",
    "            ok = ok + 1\n",
    "            check = True\n",
    "            if coordinate == -1 :\n",
    "                ok = ok - 1\n",
    "                if not equalsTextList(proper.split(),loc) and len(loc)>0:\n",
    "                    coordinate = geoNamesSearch(locateFormed(loc))\n",
    "                    if coordinate != -1:\n",
    "                        ok = ok + 1\n",
    "                        check = False\n",
    "                    print(\"geoNames:\",coordinate)\n",
    "\n",
    "                    if check:\n",
    "                        debut = loc[:len(loc) // 2]\n",
    "                        fin = loc[len(loc) // 2:]\n",
    "\n",
    "                        coordinate = middleCheck(debut,fin)\n",
    "                        if coordinate != -1:\n",
    "                            ok = ok + 1\n",
    "                        print(\"geonames:\",coordinate)\n",
    "                elif len(loc)>1:\n",
    "                    debut = loc[:len(loc) // 2]\n",
    "                    fin = loc[len(loc) // 2:]\n",
    "\n",
    "                    coordinate = middleCheck(debut, fin)\n",
    "                    if coordinate != -1:\n",
    "                        ok = ok + 1\n",
    "                    print(\"geonames:\", coordinate)\n",
    "\n",
    "        print(\"-------------------------------------\")\n",
    "        if coordinate!=-1 and len(coordinate)== 6:\n",
    "            posts.append([str(post.title), afterClean, str(post.subreddit), \"\"+str(post.url), str(post.selftext).strip(' \\\\'),coordinate[0],float(coordinate[1]),float(coordinate[2]),coordinate[3],coordinate[4], coordinate[5]])\n",
    "\n",
    "        if coordinate[4] == \"US\":\n",
    "            addInUsa(afterClean)\n",
    "\n",
    "    posts = pd.DataFrame(posts,columns=['title', 'afterClean', 'subreddit', 'url', 'body','location','longitude','latitude','contryName','contryCode','name'])\n",
    "    print(ok,\"Trouv√©s sur\",limit)\n",
    "    posts.to_json(\"fusion.json\", orient='index')\n",
    "    fusion()\n",
    "\n",
    "collectionFromReddit()\n",
    "\n",
    "\n",
    "#lexical = nltk.word_tokenize(\"National Parc of Jacques-Cartier\")\n",
    "#lexical = nltk.pos_tag(lexical)\n",
    "#print(\"lexical:\",lexical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
